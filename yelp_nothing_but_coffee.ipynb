{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "from spacy.tokens import Token\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df_nbc.pickle', 'rb') as handle:\n",
    "    df_nbc = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_dates</th>\n",
       "      <th>review_ratings</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-15</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Cute place to study  ! They have individuals t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Love the rose croissant here, and the drinks a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Time* Around 5pm on a Tuesday. \\n\\nWait* None....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Okay, you know how there are a million artisan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Everything but the parking situation is great ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_dates review_ratings  \\\n",
       "0   2020-02-15            5.0   \n",
       "1   2020-03-04            4.0   \n",
       "2   2020-03-03            4.0   \n",
       "3   2020-02-28            4.0   \n",
       "4   2020-01-18            5.0   \n",
       "\n",
       "                                             reviews  \n",
       "0  Cute place to study  ! They have individuals t...  \n",
       "1  Love the rose croissant here, and the drinks a...  \n",
       "2  Time* Around 5pm on a Tuesday. \\n\\nWait* None....  \n",
       "3  Okay, you know how there are a million artisan...  \n",
       "4  Everything but the parking situation is great ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nbc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# products on their menu\n",
    "products = ['espresso', 'latte', 'americano', 'cappucino', 'cortado', 'matcha', 'tea', 'chai', \n",
    "            'lemonade', 'ade', 'salad', 'toast', 'sandwich']\n",
    "\n",
    "# add products to be custom token attribute to be able to recognize in rule based matching\n",
    "is_product_getter = lambda token: token.test in products\n",
    "Token.set_extension('is_product', getter=is_product_getter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_something_is = [{\"POS\": \"NOUN\"}, {\"POS\": \"VERB\"}, {\"POS\": \"ADV\", \"OP\": \"?\"},\n",
    "           {\"POS\": \"ADJ\"}]\n",
    "\n",
    "p_something_for = [{\"POS\": \"NOUN\"}, {\"POS\": \"ADP\"}, {\"POS\": \"VERB\"}]\n",
    "\n",
    "p_desc = [{\"POS\": \"ADJ\"}, {\"POS\": \"NOUN\"}, {\"POS\": \"NOUN\", \"OP\": \"?\"}]\n",
    "\n",
    "p_something_of = [{\"POS\": \"NOUN\"}, {\"POS\": \"ADP\"}, {\"POS\": \"DET\", \"OP\": \"?\"}, {\"POS\": \"NOUN\"}]\n",
    "\n",
    "p_something_has = [{\"POS\": \"NOUN\"}, {\"POS\": \"VERB\"}, {\"POS\": \"NOUN\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = {'something_is': p_something_is,  'something_for': p_something_for, 'desc': p_desc, \n",
    "            'something_of': p_something_of, 'something_has': p_something_has}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "for key in patterns.keys():\n",
    "    matcher.add(key, None, patterns[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I am trying to capture statements that are more descriptive that we can use as inputs into the topic model. However, notice that for descriptions that are longer than 2 words, now that I've captured the descriptions, I can probably condense them into two words (the first and the last) without losing too much meaning. For example, \"parking in the back\" - I don't need this entire statement, or n-gram, to be included in the dataset. Instead, I can condense to the bigram, \"parking back\" and still understand that this person is describing parking that's in the back. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cute place\n",
      "table for studying\n",
      "lots of plugs\n",
      "parking in the back\n",
      "back behind the store\n",
      "more selection\n",
      "selection of food\n",
      "green tea\n",
      "macchiato is amazing\n",
      "level is minimal\n",
      "suitable environment\n",
      "environment for studying\n",
      "great experience\n"
     ]
    }
   ],
   "source": [
    "matches = matcher(review_doc)\n",
    "for _, start, end in matches:\n",
    "    print(review_doc[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocess(string):\n",
    "    \n",
    "    string = string.strip()\n",
    "    string = string.lower()\n",
    "    string = re.sub('\\n', '', string)\n",
    "    \n",
    "    return string\n",
    "\n",
    "def create_word_vector(review):\n",
    "    \n",
    "    include_all = False\n",
    "    \n",
    "    review = text_preprocess(review)\n",
    "    review_doc = nlp(review)\n",
    "    \n",
    "    tokens = set()\n",
    "    \n",
    "    matches = matcher(review_doc)\n",
    "    for _, beg, end in matches:\n",
    "        \n",
    "        # get lemma form of first word in match\n",
    "        first_word = review_doc[beg].lemma_\n",
    "        # get lemma form of last word in match\n",
    "        last_word = review_doc[end-1].lemma_\n",
    "        \n",
    "        # don't include anything with pronouns\n",
    "        # might change later\n",
    "        if first_word == '-PRON-'or last_word == '-PRON-':\n",
    "            continue\n",
    "        \n",
    "        # assign first and last word alphabetically with min/max funcs\n",
    "        # e.g. we don't want both ('cute', 'place') and ('place', 'cute') in dataset, just one of them\n",
    "        word1 = min(first_word, last_word)\n",
    "        word2 = max(first_word, last_word)\n",
    "        \n",
    "        # add pair to tokens set\n",
    "        tokens.add((word1, word2))\n",
    "        \n",
    "    # if we want to include all tokens in set    \n",
    "    if include_all:\n",
    "        for token in review_doc:\n",
    "            if not token.is_stop:\n",
    "                tokens.add(token.lemma_)\n",
    "                \n",
    "    return list(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nbc['ngrams'] = df_nbc['reviews'].apply(create_word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_dates</th>\n",
       "      <th>review_ratings</th>\n",
       "      <th>reviews</th>\n",
       "      <th>ngrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-15</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Cute place to study  ! They have individuals t...</td>\n",
       "      <td>[(level, minimal), (experience, great), (lot, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Love the rose croissant here, and the drinks a...</td>\n",
       "      <td>[(high, note), (delicious, drink), (key, vibe)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Time* Around 5pm on a Tuesday. \\n\\nWait* None....</td>\n",
       "      <td>[(cup, handle), (charcoal, surprise), (interio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Okay, you know how there are a million artisan...</td>\n",
       "      <td>[(only, worker), (menu, scarce), (coffee, fanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Everything but the parking situation is great ...</td>\n",
       "      <td>[(koreatown, shop), (latte, spanish), (drink, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_dates review_ratings  \\\n",
       "0   2020-02-15            5.0   \n",
       "1   2020-03-04            4.0   \n",
       "2   2020-03-03            4.0   \n",
       "3   2020-02-28            4.0   \n",
       "4   2020-01-18            5.0   \n",
       "\n",
       "                                             reviews  \\\n",
       "0  Cute place to study  ! They have individuals t...   \n",
       "1  Love the rose croissant here, and the drinks a...   \n",
       "2  Time* Around 5pm on a Tuesday. \\n\\nWait* None....   \n",
       "3  Okay, you know how there are a million artisan...   \n",
       "4  Everything but the parking situation is great ...   \n",
       "\n",
       "                                              ngrams  \n",
       "0  [(level, minimal), (experience, great), (lot, ...  \n",
       "1  [(high, note), (delicious, drink), (key, vibe)...  \n",
       "2  [(cup, handle), (charcoal, surprise), (interio...  \n",
       "3  [(only, worker), (menu, scarce), (coffee, fanc...  \n",
       "4  [(koreatown, shop), (latte, spanish), (drink, ...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nbc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('level', 'minimal'),\n",
       " ('experience', 'great'),\n",
       " ('lot', 'plug'),\n",
       " ('study', 'table'),\n",
       " ('food', 'selection'),\n",
       " ('back', 'parking'),\n",
       " ('environment', 'suitable'),\n",
       " ('more', 'selection'),\n",
       " ('amazing', 'macchiato'),\n",
       " ('cute', 'place'),\n",
       " ('green', 'tea'),\n",
       " ('environment', 'table')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nbc['ngrams'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('drink', 'other'),\n",
       " ('cool', 'interior'),\n",
       " ('good', 'spot'),\n",
       " ('layout', 'seat'),\n",
       " ('barista', 'nice'),\n",
       " ('attention', 'what'),\n",
       " ('attention', 'much'),\n",
       " ('basic', 'drink')]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nbc['ngrams'][18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I like to judge a coffee shop by some of their most basic drinks - drip coffee, an americano, etc. and the ice americano I ordered did not disappoint. It was smooth and not too acidic, just how I like it. I didn't pay too much attention to what their menu has to offer as I had my dog with me (which I'm not entirely sure if they allows dogs - their Yelp page says yes but they didn't have any signs up. However, the barista was super nice and he was ok with my pup being there). \\n\\nThe interior was pretty cool - their layout had seats that would be a good spot to bring your friends and hang out. I'd definitely come here again to try some of their other drinks and snacks.\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nbc['reviews'][18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "s = 'the place is cute'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "place is cute\n",
      "cute place\n"
     ]
    }
   ],
   "source": [
    "s = 'the place is cute. it is a cute place'\n",
    "test_doc = nlp(s)\n",
    "matches = matcher(test_doc)\n",
    "for _, beg, end in matches:\n",
    "    print(test_doc[beg:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'the barrista was super nice'\n",
    "test_doc = nlp(s)\n",
    "matches = matcher(test_doc)\n",
    "for _, beg, end in matches:\n",
    "    print(test_doc[beg:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
